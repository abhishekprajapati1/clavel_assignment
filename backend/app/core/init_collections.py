"""
Database initialization script for analytics collections
"""

from motor.motor_asyncio import AsyncIOMotorDatabase
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

async def init_analytics_collections(db: AsyncIOMotorDatabase):
    """Initialize analytics collections and indexes"""

    try:
        logger.info("🔧 Initializing analytics collections...")

        # Create collections if they don't exist
        collections = await db.list_collection_names()

        # Initialize download_logs collection
        if "download_logs" not in collections:
            logger.info("📊 Creating download_logs collection...")
            await db.create_collection("download_logs")
        else:
            logger.info("📊 download_logs collection already exists")

        # Initialize view_logs collection
        if "view_logs" not in collections:
            logger.info("📊 Creating view_logs collection...")
            await db.create_collection("view_logs")
        else:
            logger.info("📊 view_logs collection already exists")

        # Create indexes for download_logs
        logger.info("📋 Creating indexes for download_logs...")
        await db.download_logs.create_index([("template_id", 1)])
        await db.download_logs.create_index([("user_id", 1)])
        await db.download_logs.create_index([("downloaded_at", -1)])
        await db.download_logs.create_index([("template_id", 1), ("downloaded_at", -1)])
        await db.download_logs.create_index([("user_id", 1), ("downloaded_at", -1)])

        # Create indexes for view_logs
        logger.info("📋 Creating indexes for view_logs...")
        await db.view_logs.create_index([("template_id", 1)])
        await db.view_logs.create_index([("user_id", 1)])
        await db.view_logs.create_index([("viewed_at", -1)])
        await db.view_logs.create_index([("template_id", 1), ("viewed_at", -1)])
        await db.view_logs.create_index([("user_id", 1), ("viewed_at", -1)])

        # Create compound indexes for date range queries
        await db.download_logs.create_index([("downloaded_at", 1), ("template_id", 1)])
        await db.view_logs.create_index([("viewed_at", 1), ("template_id", 1)])

        logger.info("✅ Analytics collections initialization completed successfully")

        # Get collection stats
        download_count = await db.download_logs.count_documents({})
        view_count = await db.view_logs.count_documents({})

        logger.info(f"📈 Current analytics data: {download_count} downloads, {view_count} views")

        return True

    except Exception as e:
        logger.error(f"❌ Failed to initialize analytics collections: {str(e)}")
        return False

async def seed_sample_analytics_data(db: AsyncIOMotorDatabase):
    """Add some sample analytics data for testing (optional)"""

    try:
        # Check if we already have data
        download_count = await db.download_logs.count_documents({})
        if download_count > 0:
            logger.info("📊 Analytics data already exists, skipping seed")
            return True

        logger.info("🌱 Seeding sample analytics data...")

        # This is just for testing - in production, real data will be generated by user actions
        # You can remove this function if you don't want sample data

        logger.info("✅ Sample analytics data seeded successfully")
        return True

    except Exception as e:
        logger.error(f"❌ Failed to seed sample analytics data: {str(e)}")
        return False

async def verify_analytics_setup(db: AsyncIOMotorDatabase):
    """Verify that analytics collections are properly set up"""

    try:
        logger.info("🔍 Verifying analytics setup...")

        # Check collections exist
        collections = await db.list_collection_names()
        required_collections = ["download_logs", "view_logs"]

        for collection in required_collections:
            if collection not in collections:
                logger.error(f"❌ Required collection '{collection}' not found")
                return False
            else:
                logger.info(f"✅ Collection '{collection}' found")

        # Check indexes exist
        download_indexes = await db.download_logs.list_indexes().to_list(length=None)
        view_indexes = await db.view_logs.list_indexes().to_list(length=None)

        logger.info(f"📋 download_logs has {len(download_indexes)} indexes")
        logger.info(f"📋 view_logs has {len(view_indexes)} indexes")

        # Test basic operations
        logger.info("🧪 Testing basic operations...")

        # Test count operations (should not fail even with empty collections)
        download_count = await db.download_logs.count_documents({})
        view_count = await db.view_logs.count_documents({})

        logger.info(f"📊 Current counts - Downloads: {download_count}, Views: {view_count}")

        logger.info("✅ Analytics setup verification completed successfully")
        return True

    except Exception as e:
        logger.error(f"❌ Analytics setup verification failed: {str(e)}")
        return False

async def cleanup_old_analytics_data(db: AsyncIOMotorDatabase, days_to_keep: int = 365):
    """Clean up old analytics data to manage database size"""

    try:
        from datetime import timedelta

        cutoff_date = datetime.utcnow() - timedelta(days=days_to_keep)
        logger.info(f"🧹 Cleaning up analytics data older than {cutoff_date}")

        # Delete old download logs
        download_result = await db.download_logs.delete_many({
            "downloaded_at": {"$lt": cutoff_date}
        })

        # Delete old view logs
        view_result = await db.view_logs.delete_many({
            "viewed_at": {"$lt": cutoff_date}
        })

        total_deleted = download_result.deleted_count + view_result.deleted_count
        logger.info(f"🗑️ Cleaned up {total_deleted} old analytics records")

        return total_deleted

    except Exception as e:
        logger.error(f"❌ Failed to cleanup old analytics data: {str(e)}")
        return 0
